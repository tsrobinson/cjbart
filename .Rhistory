max=max(get(feature))
)
#calculate p for each value of feature
dd_data$p<-dd_data$n/nrow(data)
#compute IG
IG<-e0-sum(dd_data$p*dd_data$e)
return(IG)
}
IG_numeric(real, "X1", "Y", bins=5)
IG_numeric(btstp, "X1", "Y", bins=5)
IG_numeric(real, "X1", "Y", bins=10)
IG_numeric(btstp, "X1", "Y", bins=10)
IG_numeric(real, "X1", "Y", bins=100)
IG_numeric(btstp, "X1", "Y", bins=100)
IG_numeric(real, "X1", "Y", bins=100)
IG_numeric(btstp, "X1", "Y", bins=100)
IG_numeric(real, "X2", "Y", bins=100)
IG_numeric(btstp, "X2", "Y", bins=100)
IG_numeric(btstp, "X3", "Y", bins=100)
IG_numeric(real, "X3", "Y", bins=100)
IG_numeric(btstp, "X3", "Y", bins=100)
IG_numeric(real, "X4", "Y", bins=100)
IG_numeric(btstp, "X4", "Y", bins=100)
IG_numeric(real, "X4", "Y", bins=5)
IG_numeric(btstp, "X4", "Y", bins=5)
IG_numeric(real, "X5", "Y", bins=5)
IG_numeric(btstp, "X5", "Y", bins=5)
data(setosa)
data(iris)
unique(iris$Species)
summary(real$Y)
dgp <- function(n) {
X <- data.frame(X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n),
X4 = rnorm(n),
X5 = rnorm(n))
rand_coefs <- runif(17)
X$Y <- rand_coefs[1] +
rand_coefs[2]*X$X1^2 +
rand_coefs[3]*X$X2^2 +
rand_coefs[4]*X$X3^2 +
rand_coefs[5]*X$X4^2 +
rand_coefs[6]*X$X5^2 +
rand_coefs[7]*X$X1*X$X2 +
rand_coefs[8]*X$X1*X$X3 +
rand_coefs[9]*X$X1*X$X4 +
rand_coefs[10]*X$X1*X$X5 +
rand_coefs[11]*X$X2*X$X3 +
rand_coefs[12]*X$X2*X$X4 +
rand_coefs[13]*X$X2*X$X5 +
rand_coefs[14]*X$X3*X$X4 +
rand_coefs[15]*X$X3*X$X5 +
rand_coefs[16]*X$X4*X$X5 +
rand_coefs[17]*X$X1*X$X2*X$X3*X$X4*X$X5
return(X)
}
real <- dgp(100000)
real
real$Y
summary(real$Y)
1/(1+exp(-real$Y))
summary(1/(1+exp(-real$Y)))
table(real$Y)/length(real$Y)
dgp <- function(n) {
X <- data.frame(X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n),
X4 = rnorm(n),
X5 = rnorm(n))
rand_coefs <- runif(17)
X$Y <- rand_coefs[1] +
rand_coefs[2]*X$X1^2 +
rand_coefs[3]*X$X2^2 +
rand_coefs[4]*X$X3^2 +
rand_coefs[5]*X$X4^2 +
rand_coefs[6]*X$X5^2 +
rand_coefs[7]*X$X1*X$X2 +
rand_coefs[8]*X$X1*X$X3 +
rand_coefs[9]*X$X1*X$X4 +
rand_coefs[10]*X$X1*X$X5 +
rand_coefs[11]*X$X2*X$X3 +
rand_coefs[12]*X$X2*X$X4 +
rand_coefs[13]*X$X2*X$X5 +
rand_coefs[14]*X$X3*X$X4 +
rand_coefs[15]*X$X3*X$X5 +
rand_coefs[16]*X$X4*X$X5 +
rand_coefs[17]*X$X1*X$X2*X$X3*X$X4*X$X5
return(X)
}
real <- dgp(100000)
btstp <- dgp(1000)[sample(1:1000, 100000,replace = TRUE),]
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y)
summary(dgp(100000)$Y
summary(dgp(100000)$Y)
install.packages("ForeCA")
library(ForeCA)
density(real$Y)
continuous_entropy(density(real$Y),0,1)
continuous_entropy(density(real$Y)$y,0,1)
density(real$Y)$y
density(real$Y)
density(real$Y)$y
?density
integrate(density(real$Y)$y)
dgp <- function(n) {
X <- data.frame(X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n),
X4 = rnorm(n),
X5 = rnorm(n))
rand_coefs <- runif(17)
X$Y <- rand_coefs[1] +
rand_coefs[2]*X$X1^2 +
rand_coefs[3]*X$X2^2 +
rand_coefs[4]*X$X3^2 +
rand_coefs[5]*X$X4^2 +
rand_coefs[6]*X$X5^2 +
rand_coefs[7]*X$X1*X$X2 +
rand_coefs[8]*X$X1*X$X3 +
rand_coefs[9]*X$X1*X$X4 +
rand_coefs[10]*X$X1*X$X5 +
rand_coefs[11]*X$X2*X$X3 +
rand_coefs[12]*X$X2*X$X4 +
rand_coefs[13]*X$X2*X$X5 +
rand_coefs[14]*X$X3*X$X4 +
rand_coefs[15]*X$X3*X$X5 +
rand_coefs[16]*X$X4*X$X5 +
rand_coefs[17]*X$X1*X$X2*X$X3*X$X4*X$X5
X$P <- 1/(1+exp(-X$Y))
return(X)
}
real <- dgp(100000)
btstp <- dgp(1000)[sample(1:1000, 100000,replace = TRUE),]
dgp <- function(n) {
X <- data.frame(X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n),
X4 = rnorm(n),
X5 = rnorm(n))
rand_coefs <- runif(17)
X$Y <- rand_coefs[1] +
rand_coefs[2]*X$X1^2 +
rand_coefs[3]*X$X2^2 +
rand_coefs[4]*X$X3^2 +
rand_coefs[5]*X$X4^2 +
rand_coefs[6]*X$X5^2 +
rand_coefs[7]*X$X1*X$X2 +
rand_coefs[8]*X$X1*X$X3 +
rand_coefs[9]*X$X1*X$X4 +
rand_coefs[10]*X$X1*X$X5 +
rand_coefs[11]*X$X2*X$X3 +
rand_coefs[12]*X$X2*X$X4 +
rand_coefs[13]*X$X2*X$X5 +
rand_coefs[14]*X$X3*X$X4 +
rand_coefs[15]*X$X3*X$X5 +
rand_coefs[16]*X$X4*X$X5 +
rand_coefs[17]*X$X1*X$X2*X$X3*X$X4*X$X5
X$P <- 1/(1+exp(-X$Y))
X$Y_bin <- rbinom(n, 1, X$P)
return(X)
}
real <- dgp(100000)
btstp <- dgp(1000)[sample(1:1000, 100000,replace = TRUE),]
real$Y_bin
X$Y_bin <- ifelse(rbinom(n, 1, X$P) == 1, "A","B")
return(X)
dgp <- function(n) {
X <- data.frame(X1 = rnorm(n),
X2 = rnorm(n),
X3 = rnorm(n),
X4 = rnorm(n),
X5 = rnorm(n))
rand_coefs <- runif(17)
X$Y <- rand_coefs[1] +
rand_coefs[2]*X$X1^2 +
rand_coefs[3]*X$X2^2 +
rand_coefs[4]*X$X3^2 +
rand_coefs[5]*X$X4^2 +
rand_coefs[6]*X$X5^2 +
rand_coefs[7]*X$X1*X$X2 +
rand_coefs[8]*X$X1*X$X3 +
rand_coefs[9]*X$X1*X$X4 +
rand_coefs[10]*X$X1*X$X5 +
rand_coefs[11]*X$X2*X$X3 +
rand_coefs[12]*X$X2*X$X4 +
rand_coefs[13]*X$X2*X$X5 +
rand_coefs[14]*X$X3*X$X4 +
rand_coefs[15]*X$X3*X$X5 +
rand_coefs[16]*X$X4*X$X5 +
rand_coefs[17]*X$X1*X$X2*X$X3*X$X4*X$X5
X$P <- 1/(1+exp(-X$Y))
X$Y_bin <- ifelse(rbinom(n, 1, X$P) == 1, "A","B")
return(X)
}
real <- dgp(100000)
btstp <- dgp(1000)[sample(1:1000, 100000,replace = TRUE),]
real$Y_bin
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
entropy(real$Y_bin)
entropy(btstp$Y_bin)
IG_numeric<-function(data, feature, target, bins=4) {
#Strip out rows where feature is NA
data<-data[!is.na(data[,feature]),]
#compute entropy for the parent
e0<-entropy(data[,target])
data$cat<-cut(data[,feature], breaks=bins, labels=c(1:bins))
#use dplyr to compute e and p for each value of the feature
dd_data <- data %>% group_by(cat) %>% summarise(e=entropy(get(target)),
n=length(get(target)),
min=min(get(feature)),
max=max(get(feature))
)
#calculate p for each value of feature
dd_data$p<-dd_data$n/nrow(data)
#compute IG
IG<-e0-sum(dd_data$p*dd_data$e)
return(IG)
}
IG_numeric(real, "X5", "Y_bin", bins=5)
IG_numeric(btstp, "X5", "Y_bin", bins=5)
IG_numeric(real, "X1", "Y_bin", bins=5)
IG_numeric(btstp, "X1", "Y_bin", bins=5)
entr_diff <- sapply(1:1000, function (x) {
real <- dgp(100000)
btstp <- dgp(1000)[sample(1:1000, 100000,replace = TRUE),]
return(entropy(real$Y_bin) - entropy(btstp$Y_bin))
})
entr_diff <- sapply(1:1000, function (x) {
cat("\r",x)
real <- dgp(100000)
btstp <- dgp(1000)[sample(1:1000, 100000,replace = TRUE),]
return(entropy(real$Y_bin) - entropy(btstp$Y_bin))
})
plot(density(entr_diff))
summary(entr_diff)
ggplot(entr_diff)
ggplot(as.data.frame(entr_diff))
ggplot(as.data.frame(entr_diff)) + geom_histogram()
ggplot(as.data.frame(entr_diff)) + geom_density()
as.data.frame(entr_diff)
ggplot(as.data.frame(entr_diff), aes(x = "entr_diff")) + geom_density()
ggplot(as.data.frame(entr_diff), aes(x = "entr_diff")) + geom_density()
plot(x=1)
s = exp(-.8633598 - .2526442)/(1+exp(-.8633598 - .2526442))
w = exp(-.3582649 - .2526442)/(1+exp(-.3582649 - .2526442))
e = exp(-.2526442)/(1+exp(-.2526442))
e2 = 1 - s -w
s = 1/(1+exp(-(-.8633598 - .2526442)))
w =1/(1+exp(-(-.3582649 - .2526442)))
cut(seq(1:1000), breaks = k)
cut(seq(1:1000), breaks = 10)
cut(seq(1:1000), breaks = 10, labels = FALSE)
library(mlbench)
library(class)
data(Sonar)
View(Sonar)
Sonar$class_dummy <- as.numeric(as.factor(Sonar$Class))
Sonar$class_dummy
View(Sonar)
Sonar <- Sonar[complete.cases(Sonar), cols]
cols <- c(1,2,62)
Sonar <- Sonar[complete.cases(Sonar), cols]
k = 5
data(Sonar)
Sonar$class_dummy <- as.numeric(as.factor(Sonar$Class))
cols <- c(1,2,62)
Sonar <- Sonar[complete.cases(Sonar), cols]
Sonar$group = cut(seq(1, nrow(Sonar)), breaks = k, labels = FALSE)
c <- c(1,10,50,100,200)
Sonar$group = cut(seq(1, nrow(Sonar)), breaks = k, labels = FALSE)
misclassification <- as.data.frame(matrix(99, nrow = k, ncol = length(c)))
View(misclassification)
library(mlbench)
library(class)
k = 5
data(Sonar)
Sonar$class_dummy <- as.numeric(as.factor(Sonar$Class))
cols <- c(1,2,62)
Sonar <- Sonar[complete.cases(Sonar), cols]
c <- c(1,10,50,100,200)
Sonar$group = cut(seq(1, nrow(Sonar)), breaks = k, labels = FALSE)
misclassification <- as.data.frame(matrix(99, nrow = k, ncol = length(c)))
for (i in 1:k) {
sonar_train <- subset(Sonar, group != i)
sonar_test <- subset(Sonar, group == i)
sonar_train$group <- NULL
sonar_test$group <- NULL
for (n in 1:length(c)) {
pred <- knn(sonar_train, sonar_test, sonar_train$class_dummy, k=n)
misclassification[i,n] <- mean(sonar_test$class_dummy != pred)
}
}
View(misclassification)
View(sonar_test)
View(sonar_train)
View(sonar_test)
View(Sonar)
library(mlbench)
library(class)
k = 5
data(Sonar)
Sonar$class_dummy <- as.numeric(as.factor(Sonar$Class))
cols <- c(1,2,62)
Sonar <- Sonar[complete.cases(Sonar), cols]
c <- c(1,10,50,100,200)
Sonar = Sonar[sample(1:nrow(Sonar)), ]
Sonar$group = cut(seq(1, nrow(Sonar)), breaks = k, labels = FALSE)
misclassification <- as.data.frame(matrix(99, nrow = k, ncol = length(c)))
for (i in 1:k) {
sonar_train <- subset(Sonar, group != i)
sonar_test <- subset(Sonar, group == i)
sonar_train$group <- NULL
sonar_test$group <- NULL
for (n in 1:length(c)) {
pred <- knn(sonar_train, sonar_test, sonar_train$class_dummy, k=n)
misclassification[i,n] <- mean(sonar_test$class_dummy != pred)
}
}
library(mlbench)
library(class)
k = 5
data(Sonar)
Sonar$class_dummy <- as.numeric(as.factor(Sonar$Class))
cols <- c(1,2,62)
Sonar <- Sonar[complete.cases(Sonar), cols]
c <- c(1,10,50,100,200)
library(mlbench)
library(class)
k = 5
data(Sonar)
data(Sonar)
Sonar$class_dummy <- as.numeric(as.factor(Sonar$Class))
cols <- c(1,2,62)
Sonar <- Sonar[complete.cases(Sonar), cols]
c <- c(1,10,50,100,200)
Sonar = Sonar[sample(1:nrow(Sonar)), ]
View(Sonar)
Sonar$group = cut(seq(1, nrow(Sonar)), breaks = k, labels = FALSE)
misclassification <- as.data.frame(matrix(99, nrow = k, ncol = length(c)))
for (i in 1:k) {
sonar_train <- subset(Sonar, group != i)
sonar_test <- subset(Sonar, group == i)
sonar_train$group <- NULL
sonar_test$group <- NULL
for (n in 1:length(c)) {
pred <- knn(sonar_train, sonar_test, sonar_train$class_dummy, k=n)
misclassification[i,n] <- mean(sonar_test$class_dummy != pred)
}
}
View(misclassification)
View(Sonar)
ggplot(Sonar, aes(x= V1, y = V2, color = class_dummy)) + geom_point()
library(tidyverse)
ggplot(Sonar, aes(x= V1, y = V2, color = class_dummy)) + geom_point()
sonar_train
sonar_test
knn(sonar_train, sonar_test, sonar_train$class_dummy, k=n)
pred
sonar_test
?knn
sonar_test
sonar_train
devtools::install_github("tsrobinson/cjbart")
library(cjbart)
?cjbart::IMCE
tools::R_user_dir()
tools::R_user_dir("rMIDAS")
ls(tools::R_user_dir("rMIDAS"))
ls()
################################################################################
##    Replication script for:
##      How to detect heterogeneity in conjoint experiments
##
##    Authors:
##      Thomas Robinson (LSE; t.robinson7@lse.ac.uk)
##      Raymond Duch (Nuffield College, Oxford)
##
################################################################################
##
##    Please see README for replication environment, package versions,
##    and runtimes.
##
################################################################################
#### 0. Package dependencies ####
library(tidyverse)
library(cowplot)
library(ggpubr)
library(randomForestSRC)
library(rpart)
library(rpart.plot)
library(broom)
library(xtable)
library(cregg)
library(grf)
## ggrgl requires non-CRAN installs of the following dependencies:
# remotes::install_github('coolbutuseless/devout')
# remotes::install_github('coolbutuseless/devoutrgl')
# remotes::install_github('coolbutuseless/triangular')
# remotes::install_github('coolbutuseless/snowcrash')
# remotes::install_github('coolbutuseless/cryogenic')
# remotes::install_github('coolbutuseless/ggrgl', ref='main')
# library(ggrgl)
# install.packages('cjbart') - CRAN version 0.3.0
library(cjbart)
## Test install
# cjbart_runs <- cjbart(data.frame(Y = rbinom(1,10,0.5),
#                                  X1 = runif(10), X2 = runif(10),
#                                  id = 1:5),
#                       Y = "Y", id = "id")
t_start <- Sys.time()
RNGkind("L'Ecuyer-CMRG")
set.seed(99L)
# Function for simulating subject preferences and resulting conjoint data
preference_sim <- function(subjects = 500, rounds = 5, seed = 89) {
set.seed(seed)
# Define individual-level utilities
utilities <- data.frame(id = 1:subjects,
c1 = rbinom(subjects, 1, 0.5),
c2 = runif(subjects, -1,1)) %>%
mutate(X1_1 = ifelse(c1 == 1,
rnorm(subjects, 1, sd = 1),
rnorm(subjects, -1, sd = 1)),
X2_1 = rnorm(subjects, abs(c2-0.2), sd = 1),
X3_1 = rnorm(subjects, 0,sd = 0.5))
# Use utilities to determine hypothetical conjoint behaviour
conjoint_data <- data.frame(id = rep(1:subjects, each = rounds*2),
round = rep(1:rounds, each = 2),
profile = 1:2,
X1 = rbinom(subjects*rounds*2, 1, 0.5),
X2 = rbinom(subjects*rounds*2, 1, 0.5),
X3 = rbinom(subjects*rounds*2, 1, 0.5)) %>%
left_join(utilities, by = "id") %>%
mutate(U = X1*X1_1 + X2*X2_1 + X3*X3_1 + rnorm(subjects*rounds*2, 0,0.0005)) %>%
group_by(id, round) %>%
mutate(Y = ifelse(U == max(U),1,0)) %>%
ungroup()
print(head(conjoint_data))
# Mutate data for cleaner presentation
train_data <- conjoint_data %>% select(id, X1, X2, X3, c1, c2, Y) %>%
mutate(X1 = ifelse(X1 == 1, "A1: Binary heterogeneity (c1)","a"),
X2 = ifelse(X2 == 1, "A2: Interval heterogeneity (c2)","c"),
X3 = ifelse(X3 == 1, "A3: Random heterogeneity","e"))
# Run heterogeneity model
pref_mod <- cjbart(train_data, Y = "Y", id = "id")
# Generate IMCES
het_detect <- IMCE(train_data, pref_mod,
attribs = c("X1","X2","X3"),
ref_levels = c("a","c","e"),
cores = 8)
return(het_detect)
}
# Run simulation example
example_sim <- preference_sim(seed = 89)
# Generate plot
plot_c1 <- plot(example_sim) +
aes(color = as.factor(c1)) +
facet_wrap(~level, ncol = 2) +
scale_color_manual(values = c("dodgerblue2","firebrick2")) +
labs(x = "", color = expression(c[1])) +
guides(color = guide_legend(title.position="top", title.hjust = 0.5)) +
theme(legend.position = c(0.75,0.25),
legend.direction = "horizontal",
legend.background = element_rect(color = "darkgray"))
plot(plot_c1)
RNGkind("L'Ecuyer-CMRG")
set.seed(1)
rnorm(5)
setwd("~/db_personal/cjbart")
